# Leveraging Collaborative Filtering for Personalized Practice in Computer-Based Assessments

Computer-based homework and assessments have become increasingly prevalent in undergraduate STEM courses, offering automatic grading and instant feedback to accommodate large student populations. While randomization features are commonly used to combat collaborative cheating, less attention has been given to leveraging the existing data within online learning systems to personalize question selection based on individual student needs. This project explores the potential of collaborative filtering (CF)-based recommender systems to predict students' performance on new, unseen questions using their past scores, thereby offering a pathway to personalized question selection. For example, the predicted scores can be used to create a personalized set of practice questions, focusing on areas where the student has lower predicted scores and has not yet achieved mastery. 

We evaluated six CF models against a baseline model using Dietterich's 5x2 cross-validation method on two datasets from a computer systems course. The models were assessed on Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), with statistical significance determined via a paired t-test. Our findings indicate that all CF models significantly outperformed the baseline, with the SVD++ model consistently delivering the most robust results. These results suggest that CF models can effectively predict student performance on unseen questions, enabling personalized question recommendations within online learning systems. Future research will evaluate the effectiveness of this personalization mechanism through a user study, with the goal to capture the overall student experience and determine whether students perceive this form of personalization as beneficial to their learning.

We provide our [script](https://github.com/rmahinpei/personalized-practice/blob/main/cf_models_evaluation.ipynb) for instructors interested in applying this analysis to their own datasets in this repository. We are also happy to provide access to the anonymized datasets used in our analysis upon request.
